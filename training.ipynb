{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1ddf5a",
   "metadata": {},
   "source": [
    "# 고양이 그림 점수 생성을 위한 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b27f7da",
   "metadata": {},
   "source": [
    "### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5afaa5",
   "metadata": {},
   "source": [
    "### 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df906bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list = os.listdir('/Users/kimhongseok/squid_game_heaven/data/train/cat')\n",
    "\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    root = os.path.join('/Users/kimhongseok/squid_game_heaven/data/train/cat', train_img_list[i])\n",
    "    img = Image.open(root)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b8f29",
   "metadata": {},
   "source": [
    "# Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0060e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir, classes, transform):\n",
    "        super().__init__()\n",
    "        self.data = list()\n",
    "        self.transform = transform\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            root_dir = os.path.join(dir, classes[i])\n",
    "            img_list = os.listdir(root_dir)\n",
    "            for img in img_list:\n",
    "                if '.DS_Store' not in img:\n",
    "                    self.data.append((os.path.join(root_dir, img), i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        img = Image.open(img).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b295ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.Resize((480, 480)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# dataset, dataloader 생성\n",
    "train_dataset = CustomDataset('data/train', ['cat', 'non_cat'], transforms)\n",
    "valid_dataset = CustomDataset('data/valid', ['cat', 'non_cat'], transforms)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6726d",
   "metadata": {},
   "source": [
    "# Train, Validation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d97910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dataloader, train_dataset, criterion, optimizer, epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    tbar = tqdm(train_dataloader)\n",
    "    for images, labels in tbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        max_prob, preds = torch.max(probs, 1)\n",
    "        train_accuracy += (preds == labels).sum().item()\n",
    "\n",
    "        tbar.set_description(f'Epoch/Epochs [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_accuracy /= len(train_dataset)\n",
    "\n",
    "    return model, train_loss, train_accuracy\n",
    "\n",
    "def evaluation(model, valid_dataloader, valid_dataset, criterion, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tbar = tqdm(valid_dataloader)\n",
    "        for images, labels in tbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            max_prob, preds = torch.max(probs, 1)\n",
    "            valid_accuracy += (preds == labels).sum().item()\n",
    "\n",
    "            tbar.set_description(f'Epoch/Epochs [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "\n",
    "    valid_loss /= len(valid_dataset)\n",
    "    valid_accuracy /= len(valid_dataset)\n",
    "\n",
    "    return valid_loss, valid_accuracy\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, num_epochs):\n",
    "    model.to(device)\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, epoch, num_epochs)\n",
    "        valid_loss, valid_accuracy = evaluation(model, valid_dataloader, valid_dataset, criterion, epoch, num_epochs)\n",
    "\n",
    "        print(f'Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Valid Loss: {valid_loss}, Valid Accuracy: {valid_accuracy}')\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model, 'best_model.pth')\n",
    "            print(f'Best model updated at epoch {epoch + 1} (Valid Loss: {valid_loss:.4f})')\n",
    "    \n",
    "    torch.save(model, 'last_model.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b29a57",
   "metadata": {},
   "source": [
    "# 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    'resnet18',\n",
    "    pretrained=True,\n",
    "    num_classes=2\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 학습 유무 조정\n",
    "\n",
    "'''\n",
    "# 마지막 레이어를 제외한 모든 파라미터는 학습되지 않게 설정\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "model = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41372319",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset('/Users/kimhongseok/squid_game_heaven/data/valid', ['cat', 'non_cat'], transforms)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    tbar = tqdm(test_dataloader)\n",
    "    for images, _ in tbar:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        total_preds.extend(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e069c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(test_dataset[i][0].permute(1, 2, 0))\n",
    "    plt.title(f'Score: {total_preds[i][0].cpu().item()*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1. 모델 평가 모드 전환\n",
    "model.eval()\n",
    "\n",
    "# 2. 단일 이미지 불러오기\n",
    "image_path = \"/Users/kimhongseok/squid_game_heaven/data/valid/cat/25_17.jpg\"  # 판별할 이미지 경로\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 3. 전처리 (모델 학습 시 사용한 전처리와 동일해야 함)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 모델 입력 크기에 맞춤\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image = transform(image).unsqueeze(0)  # 배치 차원 추가 (1, C, H, W)\n",
    "image = image.to(device)\n",
    "\n",
    "# 4. 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "print(\"예측 클래스:\", predicted_class)\n",
    "print(\"클래스별 확률:\", probs.cpu().numpy()[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
